#!/usr/bin/env python3
"""
GST Intelligence Platform - Main Application (Fixed Version)
Enhanced with PostgreSQL database and AI-powered insights
All missing endpoints and database fixes included
"""

import os
import re
import asyncio
import asyncpg
import hashlib
import secrets
import time
import logging
import json
import httpx
import uvicorn
import csv
from datetime import datetime, timedelta, date
from collections import defaultdict
from typing import Dict, Any, Optional, List, Union
from fastapi import FastAPI, Request, Form, Depends, HTTPException, status, Response
from fastapi.responses import HTMLResponse, RedirectResponse, JSONResponse, StreamingResponse, FileResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from io import BytesIO, StringIO
from dotenv import load_dotenv
from anthro_ai import get_anthropic_synopsis
from validators import EnhancedDataValidator, get_validation_rules
from dataclasses import dataclass, asdict
from contextlib import asynccontextmanager
from decimal import Decimal

class DateTimeEncoder(json.JSONEncoder):
    """Custom JSON encoder that handles datetime objects"""
    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)

def safe_json_response(data):
    """Create JSONResponse with datetime handling"""
    return JSONResponse(
        content=json.loads(json.dumps(data, cls=DateTimeEncoder))
    )

def serialize_for_template(obj):
    """Convert objects to JSON-serializable format"""
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    elif isinstance(obj, Decimal):
        return float(obj)
    elif isinstance(obj, dict):
        return {key: serialize_for_template(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [serialize_for_template(item) for item in obj]
    elif hasattr(obj, '_mapping'):  # Database row object
        return {key: serialize_for_template(value) for key, value in dict(obj).items()}
    else:
        return obj

# Load environment variables
load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from weasyprint import HTML
    WEASYPRINT_AVAILABLE = True
except ImportError:
    logger.warning("WeasyPrint not available - PDF generation disabled")
    WEASYPRINT_AVAILABLE = False

# Environment Configuration
try:
    from api_debug_fix import (
        enhanced_gst_client, 
        enhanced_ai_client, 
        debug_api_status,
        RAPIDAPI_KEY,
        ANTHROPIC_API_KEY,
        RAPIDAPI_HOST
    )
    ENHANCED_APIS_AVAILABLE = True
    logger.info("✅ Enhanced API clients loaded successfully")
except ImportError as e:
    logger.error(f"❌ Failed to import enhanced API clients: {e}")
    ENHANCED_APIS_AVAILABLE = False
RAPIDAPI_KEY = os.getenv("RAPIDAPI_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY") 
RAPIDAPI_HOST = os.getenv("RAPIDAPI_HOST", "gst-return-status.p.rapidapi.com")
POSTGRES_DSN = "postgresql://neondb_owner:npg_i3m7wqMeHXaW@ep-fragrant-cell-a10j16o4-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require"

# Initialize FastAPI app
app = FastAPI(title="GST Intelligence Platform", version="2.0.0")
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# Add template globals
def setup_template_globals():
    """Setup global template variables"""
    templates.env.globals.update({
        'current_year': datetime.now().year,
        'app_version': "2.0.0"
    })

# Enhanced Database Manager

class FixedDatabaseManager:
    """Fixed database manager with corrected set handling"""
    
    def __init__(self, postgres_dsn: str):
        self.postgres_dsn = postgres_dsn
        self.pool = None
        self._initialized = False
        self._column_cache = {}  # Cache for column existence checks

    async def initialize(self):
        """Initialize database connection"""
        if self._initialized:
            return

        try:
            self.pool = await asyncpg.create_pool(
                dsn=self.postgres_dsn,
                min_size=2,
                max_size=20,
                max_queries=50000,
                max_inactive_connection_lifetime=300,
                command_timeout=30,
                server_settings={
                    'application_name': 'gst-intelligence-platform',
                    'timezone': 'UTC'
                }
            )
            
            # Test connection
            async with self.pool.acquire() as conn:
                await conn.execute("SELECT 1")
            
            # Cache column information
            await self._cache_table_columns()
            
            self._initialized = True
            logger.info("✅ Database initialized successfully")
            
        except Exception as e:
            logger.error(f"❌ Database initialization failed: {e}")
            raise

    async def _cache_table_columns(self):
        """Cache information about which columns exist in each table"""
        try:
            async with self.pool.acquire() as conn:
                # Get all columns for important tables
                tables_to_check = ['users', 'user_profiles', 'user_sessions', 'search_history', 'gst_search_history']
                
                for table in tables_to_check:
                    try:
                        columns = await conn.fetch("""
                            SELECT column_name 
                            FROM information_schema.columns 
                            WHERE table_name = $1 AND table_schema = 'public'
                        """, table)
                        
                        # Store as set for fast lookup
                        self._column_cache[table] = {row['column_name'] for row in columns}
                        logger.info(f"Cached {len(self._column_cache[table])} columns for {table}")
                        
                    except Exception as e:
                        logger.warning(f"Could not cache columns for {table}: {e}")
                        self._column_cache[table] = set()
                        
        except Exception as e:
            logger.warning(f"Could not cache column information: {e}")
            # Set default empty cache
            self._column_cache = {}

    def _has_column(self, table: str, column: str) -> bool:
        """Check if a table has a specific column - FIXED VERSION"""
        if not self._column_cache:
            return True  # Assume column exists if we don't have cache info
        
        table_columns = self._column_cache.get(table, set())
        if not table_columns:  # If empty set, assume column exists
            return True
        return column in table_columns  # Use 'in' operator for sets

    def _build_safe_select(self, table: str, columns: list, where_clause: str = "") -> str:
        """Build a SELECT query with only existing columns"""
        if table not in self._column_cache:
            # If we don't have cached info, assume all columns exist
            return f"SELECT {', '.join(columns)} FROM {table} {where_clause}"
        
        safe_columns = []
        for col in columns:
            if self._has_column(table, col):
                safe_columns.append(col)
            else:
                # Add a NULL placeholder for missing columns
                safe_columns.append(f"NULL as {col}")
                logger.warning(f"Column {col} not found in {table}, using NULL")
        
        return f"SELECT {', '.join(safe_columns)} FROM {table} {where_clause}"

    async def create_user(self, mobile: str, password_hash: str, salt: str, email: str = None) -> bool:
        """Create new user with safe column handling"""
        try:
            async with self.pool.acquire() as conn:
                # Check which columns exist in users table
                base_columns = ['mobile', 'password_hash', 'salt']
                base_values = [mobile, password_hash, salt]
                placeholders = ['$1', '$2', '$3']
                
                # Add optional columns if they exist
                if email and self._has_column('users', 'email'):
                    base_columns.append('email')
                    base_values.append(email)
                    placeholders.append('$4')
                
                # Add profile_data if it exists
                if self._has_column('users', 'profile_data'):
                    base_columns.append('profile_data')
                    base_values.append('{}')
                    placeholders.append(f'${len(base_values) + 1}')
                
                query = f"""
                    INSERT INTO users ({', '.join(base_columns)})
                    VALUES ({', '.join(placeholders)})
                """
                
                await conn.execute(query, *base_values)
                
                # Try to initialize user profile if table exists
                if 'user_profiles' in self._column_cache:
                    try:
                        await conn.execute(
                            "INSERT INTO user_profiles (mobile, display_name) VALUES ($1, $2)",
                            mobile, f"User {mobile[-4:]}"
                        )
                    except Exception as e:
                        logger.warning(f"Could not create user profile: {e}")
                
                logger.info(f"✅ User created successfully: {mobile}")
                return True
                
        except asyncpg.UniqueViolationError:
            logger.warning(f"⚠️ User already exists: {mobile}")
            return False
        except Exception as e:
            logger.error(f"❌ User creation failed: {e}")
            return False

    async def verify_user(self, mobile: str, password: str) -> bool:
        """Verify user credentials with safe column handling"""
        try:
            async with self.pool.acquire() as conn:
                # Build safe query for users table
                columns = ['password_hash', 'salt']
                
                if self._has_column('users', 'is_active'):
                    where_clause = "WHERE mobile = $1 AND is_active = TRUE"
                else:
                    where_clause = "WHERE mobile = $1"
                
                query = self._build_safe_select('users', columns, where_clause)
                result = await conn.fetchrow(query, mobile)
                
                if result:
                    stored_hash = result["password_hash"]
                    salt = result["salt"]
                    
                    # Hash the provided password with the stored salt
                    password_hash = hashlib.pbkdf2_hmac(
                        'sha256', 
                        password.encode('utf-8'), 
                        salt.encode('utf-8'), 
                        100000, 
                        dklen=64
                    ).hex()
                    
                    return password_hash == stored_hash
                return False
        except Exception as e:
            logger.error(f"Error verifying user: {e}")
            return False

    async def create_session(self, mobile: str, ip_address: str = None, user_agent: str = None) -> str:
        """Create new user session with safe column handling"""
        try:
            session_id = secrets.token_urlsafe(32)
            expires_at = datetime.now() + timedelta(days=30)
            
            async with self.pool.acquire() as conn:
                # Build safe insert for user_sessions
                base_columns = ['session_id', 'user_mobile', 'expires_at']
                base_values = [session_id, mobile, expires_at]
                placeholders = ['$1', '$2', '$3']
                
                # Add optional columns if they exist
                if ip_address and self._has_column('user_sessions', 'ip_address'):
                    base_columns.append('ip_address')
                    base_values.append(ip_address)
                    placeholders.append(f'${len(base_values)}')
                
                if user_agent and self._has_column('user_sessions', 'user_agent'):
                    base_columns.append('user_agent')
                    base_values.append(user_agent)
                    placeholders.append(f'${len(base_values)}')
                
                query = f"""
                    INSERT INTO user_sessions ({', '.join(base_columns)}) 
                    VALUES ({', '.join(placeholders)})
                """
                
                await conn.execute(query, *base_values)
                return session_id
        except Exception as e:
            logger.error(f"Error creating session: {e}")
            return None

    async def get_session(self, session_token: str) -> Optional[str]:
        """Get user from session token with safe column handling"""
        try:
            async with self.pool.acquire() as conn:
                # Build safe query
                columns = ['user_mobile']
                
                if self._has_column('user_sessions', 'is_active'):
                    where_clause = "WHERE session_id = $1 AND expires_at > CURRENT_TIMESTAMP AND is_active = TRUE"
                else:
                    where_clause = "WHERE session_id = $1 AND expires_at > CURRENT_TIMESTAMP"
                
                query = self._build_safe_select('user_sessions', columns, where_clause)
                result = await conn.fetchrow(query, session_token)
                
                if result:
                    # Try to update last activity if column exists
                    if self._has_column('user_sessions', 'last_activity'):
                        try:
                            await conn.execute(
                                "UPDATE user_sessions SET last_activity = CURRENT_TIMESTAMP WHERE session_id = $1",
                                session_token
                            )
                        except Exception:
                            pass  # Ignore if update fails
                    
                    return result["user_mobile"]
                return None
        except Exception as e:
            logger.error(f"Error getting session: {e}")
            return None

    async def delete_session(self, session_token: str) -> bool:
        """Delete user session with safe column handling"""
        try:
            async with self.pool.acquire() as conn:
                if self._has_column('user_sessions', 'is_active'):
                    # Soft delete by setting is_active to False
                    await conn.execute(
                        "UPDATE user_sessions SET is_active = FALSE WHERE session_id = $1",
                        session_token
                    )
                else:
                    # Hard delete
                    await conn.execute(
                        "DELETE FROM user_sessions WHERE session_id = $1",
                        session_token
                    )
                return True
        except Exception as e:
            logger.error(f"Error deleting session: {e}")
            return False

    async def update_last_login(self, mobile: str) -> bool:
        """Update user's last login timestamp with safe column handling"""
        try:
            async with self.pool.acquire() as conn:
                if self._has_column('users', 'last_login'):
                    await conn.execute(
                        "UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE mobile = $1",
                        mobile
                    )
                return True
        except Exception as e:
            logger.error(f"Error updating last login: {e}")
            return False

    async def add_search_history(self, mobile: str, gstin: str, company_name: str, compliance_score: float, search_data: dict = None, ai_synopsis: str = None) -> bool:
        """Add search to history with safe column handling - COMPLETELY FIXED"""
        try:
            async with self.pool.acquire() as conn:
                # Check what columns exist first
                existing_columns = await conn.fetch("""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name = 'search_history' AND table_schema = 'public'
                """)
                
                column_names = {row['column_name'] for row in existing_columns}
                
                # Build insert with only existing columns
                columns = ['mobile', 'gstin', 'company_name', 'compliance_score']
                values = [mobile, gstin, company_name, compliance_score]
                placeholders = ['$1', '$2', '$3', '$4']
                
                # Add optional columns if they exist
                if 'search_data' in column_names and search_data is not None:
                    columns.append('search_data')
                    values.append(json.dumps(search_data))
                    placeholders.append(f'${len(values)}')
                
                if 'ai_synopsis' in column_names and ai_synopsis is not None:
                    columns.append('ai_synopsis')
                    values.append(ai_synopsis)
                    placeholders.append(f'${len(values)}')
                
                if 'searched_at' in column_names:
                    columns.append('searched_at')
                    values.append('CURRENT_TIMESTAMP')
                    placeholders.append('CURRENT_TIMESTAMP')
                
                query = f"""
                    INSERT INTO search_history ({', '.join(columns)}) 
                    VALUES ({', '.join(placeholders)})
                    ON CONFLICT (mobile, gstin) DO UPDATE SET 
                        compliance_score = EXCLUDED.compliance_score,
                        company_name = EXCLUDED.company_name,
                        searched_at = CURRENT_TIMESTAMP
                """
                
                # Remove CURRENT_TIMESTAMP from values if it's there
                clean_values = [v for v in values if v != 'CURRENT_TIMESTAMP']
                
                await conn.execute(query, *clean_values)
                logger.info(f"✅ Search history added: {gstin} for {mobile}")
                return True
                    
        except Exception as e:
            logger.error(f"❌ Error adding search history: {e}")
            return False

    async def get_search_history(self, mobile: str, limit: int = 50) -> List[Dict]:
        """Get user search history with safe column handling - COMPLETELY FIXED"""
        try:
            async with self.pool.acquire() as conn:
                # First check what columns actually exist
                existing_columns = await conn.fetch("""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name = 'search_history' AND table_schema = 'public'
                """)
                
                column_names = {row['column_name'] for row in existing_columns}
                logger.info(f"Available columns in search_history: {column_names}")
                
                # Build query with only existing columns
                base_columns = ['gstin', 'company_name', 'compliance_score', 'searched_at']
                select_parts = []
                
                for col in base_columns:
                    if col in column_names:
                        if col == 'compliance_score':
                            select_parts.append('COALESCE(compliance_score, 0) as compliance_score')
                        else:
                            select_parts.append(col)
                    else:
                        # Add default values for missing columns
                        if col == 'compliance_score':
                            select_parts.append('0 as compliance_score')
                        elif col == 'searched_at':
                            select_parts.append('CURRENT_TIMESTAMP as searched_at')
                        else:
                            select_parts.append(f"'' as {col}")
                
                # Add optional columns if they exist
                if 'ai_synopsis' in column_names:
                    select_parts.append('COALESCE(ai_synopsis, \'\') as ai_synopsis')
                else:
                    select_parts.append('\'\' as ai_synopsis')
                
                if 'search_data' in column_names:
                    select_parts.append('search_data')
                
                query = f"""
                    SELECT {', '.join(select_parts)}
                    FROM search_history 
                    WHERE mobile = $1 
                    ORDER BY searched_at DESC 
                    LIMIT $2
                """
                
                logger.info(f"Executing query: {query}")
                
                history = await conn.fetch(query, mobile, limit)
                
                result = []
                for row in history:
                    row_dict = dict(row)
                    # Ensure all expected fields exist
                    if 'ai_synopsis' not in row_dict:
                        row_dict['ai_synopsis'] = ''
                    if 'compliance_score' not in row_dict:
                        row_dict['compliance_score'] = 0
                    if 'company_name' not in row_dict:
                        row_dict['company_name'] = 'Unknown Company'
                        
                    result.append(row_dict)
                
                logger.info(f"✅ Retrieved {len(result)} search history items for {mobile}")
                return result
                    
        except Exception as e:
            logger.error(f"❌ Error getting search history for {mobile}: {e}")
            return []

    async def get_all_searches(self, mobile: str) -> List[Dict]:
        """Get all searches for user with safe column handling"""
        try:
            async with self.pool.acquire() as conn:
                columns = ['gstin', 'company_name', 'compliance_score', 'searched_at']
                
                query = self._build_safe_select(
                    'search_history', 
                    columns, 
                    "WHERE mobile = $1 ORDER BY searched_at DESC"
                )
                
                history = await conn.fetch(query, mobile)
                return [dict(row) for row in history]
        except Exception as e:
            logger.error(f"Error getting all searches: {e}")
            return []

    async def get_user_stats(self, mobile: str) -> Dict:
        """Get user statistics with safe column handling - FIXED"""
        try:
            await self.initialize()
            async with self.pool.acquire() as conn:
                # Use a more robust query that handles missing data
                stats = await conn.fetchrow("""
                    SELECT 
                        COALESCE(COUNT(*), 0) as total_searches,
                        COALESCE(ROUND(AVG(COALESCE(compliance_score, 0))::numeric, 1), 0) as avg_compliance,
                        COALESCE(COUNT(DISTINCT COALESCE(gstin, '')), 0) as unique_companies,
                        COALESCE(COUNT(CASE 
                            WHEN searched_at >= CURRENT_DATE - INTERVAL '30 days' 
                            THEN 1 
                            ELSE NULL 
                        END), 0) as searches_this_month
                    FROM search_history 
                    WHERE mobile = $1
                """, mobile)
                
                if stats:
                    result = {
                        "total_searches": int(stats["total_searches"]) if stats["total_searches"] else 0,
                        "avg_compliance": float(stats["avg_compliance"]) if stats["avg_compliance"] else 0.0,
                        "unique_companies": int(stats["unique_companies"]) if stats["unique_companies"] else 0,
                        "searches_this_month": int(stats["searches_this_month"]) if stats["searches_this_month"] else 0
                    }
                    
                    logger.info(f"✅ User stats loaded for {mobile}: {result}")
                    return result
                else:
                    logger.warning(f"⚠️ No stats found for user {mobile}")
                    return {"total_searches": 0, "avg_compliance": 0.0, "unique_companies": 0, "searches_this_month": 0}
                    
        except Exception as e:
            logger.error(f"❌ Error getting user stats for {mobile}: {e}")
            return {"total_searches": 0, "avg_compliance": 0.0, "unique_companies": 0, "searches_this_month": 0}

    async def get_user_profile_data(self, mobile: str) -> Dict:
        """Get user profile data with safe column handling - DATETIME FIXED"""
        try:
            await self.initialize()
            async with self.pool.acquire() as conn:
                # Get basic user data without datetime issues
                try:
                    user_data = await conn.fetchrow("""
                        SELECT mobile, 
                               COALESCE(email, '') as email
                        FROM users 
                        WHERE mobile = $1
                    """, mobile)
                except Exception:
                    user_data = None
                
                # Get search statistics (these are just numbers)
                search_stats = await self.get_user_stats(mobile)
                
                # Get recent searches - handle datetime carefully
                try:
                    recent_searches_raw = await self.get_search_history(mobile, 5)
                    
                    # Convert to simple dict format without datetime serialization issues
                    recent_searches = []
                    for item in recent_searches_raw:
                        if hasattr(item, '_mapping'):
                            item_dict = dict(item)
                        else:
                            item_dict = item
                        
                        # Convert datetime to string immediately
                        if 'searched_at' in item_dict and item_dict['searched_at']:
                            if hasattr(item_dict['searched_at'], 'strftime'):
                                item_dict['searched_at_str'] = item_dict['searched_at'].strftime('%Y-%m-%d %H:%M:%S')
                            # Keep the datetime object for template use, but add string version
                        
                        recent_searches.append(item_dict)
                        
                except Exception as e:
                    logger.error(f"Error getting recent searches: {e}")
                    recent_searches = []
                
                # Format user info - NO datetime objects
                user_info = {}
                if user_data:
                    user_info = {
                        "mobile": user_data["mobile"],
                        "email": user_data.get("email", ""),
                        "created_at": None,  # Don't include datetime
                        "profile_data": {}
                    }
                else:
                    user_info = {
                        "mobile": mobile,
                        "email": "",
                        "created_at": None,
                        "profile_data": {}
                    }
                
                return {
                    "user_info": user_info,
                    "search_stats": search_stats,
                    "recent_searches": recent_searches
                }
                    
        except Exception as e:
            logger.error(f"Error getting user profile: {e}")
            return {
                "user_info": {"mobile": mobile, "email": "", "created_at": None},
                "search_stats": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0},
                "recent_searches": []
            }

    # Additional methods for loan management (if needed)
    async def get_user_loan_applications(self, mobile: str) -> List[Dict]:
        """Get user's loan applications"""
        try:
            if 'loan_applications' not in self._column_cache:
                return []  # Table doesn't exist
                
            async with self.pool.acquire() as conn:
                applications = await conn.fetch(
                    """SELECT * FROM loan_applications 
                       WHERE user_mobile = $1 
                       ORDER BY created_at DESC""",
                    mobile
                )
                return [dict(row) for row in applications]
        except Exception as e:
            logger.error(f"Error getting loan applications: {e}")
            return []

    async def get_user_active_loans(self, mobile: str) -> List[Dict]:
        """Get user's active loans"""
        try:
            if 'active_loans' not in self._column_cache:
                return []  # Table doesn't exist
                
            async with self.pool.acquire() as conn:
                loans = await conn.fetch(
                    """SELECT al.*, la.company_name, la.gstin 
                       FROM active_loans al
                       JOIN loan_applications la ON al.application_id = la.application_id
                       WHERE al.user_mobile = $1 AND al.status = 'active'
                       ORDER BY al.created_at DESC""",
                    mobile
                )
                return [dict(row) for row in loans]
        except Exception as e:
            logger.error(f"Error getting active loans: {e}")
            return []

    async def close(self):
        """Close database connections"""
        try:
            if self.pool:
                await self.pool.close()
            self._initialized = False
            logger.info("✅ Database connections closed")
        except Exception as e:
            logger.error(f"❌ Error closing database connections: {e}")

# Initialize database
db = FixedDatabaseManager(postgres_dsn=POSTGRES_DSN)

# Authentication functions
async def get_current_user(request: Request) -> Optional[str]:
    """Get current user from session"""
    session_token = request.cookies.get("session_token")
    if not session_token:
        return None
    return await db.get_session(session_token)

async def require_auth(request: Request) -> str:
    """Require authentication for protected routes"""
    user = await get_current_user(request)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_303_SEE_OTHER, 
            headers={"Location": "/login"}
        )
    return user

# Rate Limiter
class RateLimiter:
    def __init__(self, max_attempts=5, window_minutes=15):
        self.attempts = defaultdict(list)
        self.max_attempts = max_attempts
        self.window = timedelta(minutes=window_minutes)
    
    def is_allowed(self, identifier: str) -> bool:
        now = datetime.now()
        self.attempts[identifier] = [
            attempt for attempt in self.attempts[identifier]
            if now - attempt < self.window
        ]
        
        if len(self.attempts[identifier]) >= self.max_attempts:
            return False
        
        self.attempts[identifier].append(now)
        return True

# Initialize rate limiters
login_limiter = RateLimiter()
api_limiter = RateLimiter(max_attempts=60, window_minutes=1)

# GST API Client
if ENHANCED_APIS_AVAILABLE:
    api_client = enhanced_gst_client
    ai_client = enhanced_ai_client
else:
    class GSAPIClient:
        def __init__(self, api_key: str, host: str):
            self.api_key = api_key
            self.host = host
            self.headers = {
                "X-RapidAPI-Key": api_key,
                "X-RapidAPI-Host": host
            }
        
        async def fetch_gstin_data(self, gstin: str) -> Dict:
            """Fetch GSTIN data from RapidAPI"""
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(
                        f"https://{self.host}/gstin/{gstin}",
                        headers=self.headers,
                        timeout=30.0
                    )
                    
                    if response.status_code == 200:
                        data = response.json()
                        return data
                    else:
                        raise HTTPException(status_code=404, detail="Company not found")
                        
            except httpx.TimeoutException:
                raise HTTPException(status_code=504, detail="API timeout")
            except Exception as e:
                logger.error(f"GST API error: {e}")
                raise HTTPException(status_code=500, detail="API service error")

    api_client = GSAPIClient(RAPIDAPI_KEY, RAPIDAPI_HOST) if RAPIDAPI_KEY else None
    ai_client = None

# FIXED: Enhanced AI synopsis function
async def get_enhanced_ai_synopsis(company_data: dict) -> Optional[str]:
    """Get AI synopsis using enhanced client or fallback"""
    try:
        if ENHANCED_APIS_AVAILABLE and enhanced_ai_client:
            return await enhanced_ai_client.get_synopsis(company_data)
        elif ANTHROPIC_API_KEY:
            # Fallback to original anthro_ai import
            from anthro_ai import get_anthropic_synopsis
            return await get_anthropic_synopsis(company_data)
        else:
            logger.warning("No AI service available")
            return None
    except Exception as e:
        logger.error(f"AI synopsis error: {e}")
        return None

# Validation functions
def validate_mobile(mobile: str) -> tuple[bool, str]:
    return EnhancedDataValidator.validate_mobile(mobile)

def validate_gstin(gstin: str) -> bool:
    is_valid, _ = EnhancedDataValidator.validate_gstin(gstin)
    return is_valid

def validate_email(email: str) -> bool:
    is_valid, _ = EnhancedDataValidator.validate_email(email)
    return is_valid

# Compliance calculation functions
def calculate_return_due_date(return_type: str, tax_period: str, fy: str) -> datetime:
    try:
        months = {
            'January': 1, 'February': 2, 'March': 3, 'April': 4,
            'May': 5, 'June': 6, 'July': 7, 'August': 8,
            'September': 9, 'October': 10, 'November': 11, 'December': 12
        }
        
        if tax_period in months:
            month = months[tax_period]
            fy_parts = fy.split('-')
            if month >= 4:
                year = int(fy_parts[0])
            else:
                year = int(fy_parts[1])
            
            if return_type == "GSTR1":
                if month == 12:
                    due_date = datetime(year + 1, 1, 11)
                else:
                    due_date = datetime(year, month + 1, 11)
            elif return_type == "GSTR3B":
                if month == 12:
                    due_date = datetime(year + 1, 1, 20)
                else:
                    due_date = datetime(year, month + 1, 20)
            elif return_type == "GSTR9":
                year = int(fy_parts[1])
                due_date = datetime(year, 12, 31)
            else:
                return None
                
            return due_date
    except:
        return None
    
    return None

def analyze_late_filings(returns: List[Dict]) -> Dict:
    late_returns = []
    on_time_returns = []
    total_delay_days = 0
    
    for return_item in returns:
        return_type = return_item.get("rtntype")
        tax_period = return_item.get("taxp")
        fy = return_item.get("fy")
        dof = return_item.get("dof")
        
        if all([return_type, tax_period, fy, dof]):
            due_date = calculate_return_due_date(return_type, tax_period, fy)
            
            if due_date:
                try:
                    filing_date = datetime.strptime(dof, "%d/%m/%Y")
                    
                    if filing_date > due_date:
                        delay_days = (filing_date - due_date).days
                        late_returns.append({
                            'return': return_item,
                            'due_date': due_date,
                            'filing_date': filing_date,
                            'delay_days': delay_days
                        })
                        total_delay_days += delay_days
                    else:
                        on_time_returns.append(return_item)
                except:
                    pass
    
    return {
        'late_count': len(late_returns),
        'on_time_count': len(on_time_returns),
        'late_returns': late_returns,
        'total_delay_days': total_delay_days,
        'average_delay': total_delay_days / len(late_returns) if late_returns else 0
    }

def calculate_compliance_score(company_data: dict) -> float:
    """Calculate compliance score"""
    score = 100.0
    
    # Registration Status (25 points)
    if company_data.get("sts") != "Active":
        score -= 25
    
    # Filing Compliance (20 points)
    returns = company_data.get("returns", [])
    if returns:
        current_date = datetime.now()
        gstr1_returns = [r for r in returns if r.get("rtntype") == "GSTR1"]
        
        months_since_reg = 12
        if company_data.get("rgdt"):
            try:
                reg_date = datetime.strptime(company_data["rgdt"], "%d/%m/%Y")
                months_since_reg = max(1, (current_date - reg_date).days // 30)
            except:
                pass
        
        expected_returns = min(months_since_reg, 12)
        filing_ratio = min(len(gstr1_returns) / expected_returns, 1.0) if expected_returns > 0 else 0
        filing_points = int(filing_ratio * 20)
        score = score - 20 + filing_points
    else:
        score -= 20
    
    # Late Filing Analysis (25 points)
    if returns:
        late_filing_analysis = analyze_late_filings(returns)
        late_count = late_filing_analysis['late_count']
        total_returns = late_count + late_filing_analysis['on_time_count']
        
        if total_returns > 0:
            on_time_ratio = late_filing_analysis['on_time_count'] / total_returns
            late_filing_points = int(on_time_ratio * 25)
            
            avg_delay = late_filing_analysis['average_delay']
            if avg_delay > 30:
                late_filing_points = max(0, late_filing_points - 5)
            
            score = score - 25 + late_filing_points
        else:
            score -= 13
        
        company_data['_late_filing_analysis'] = late_filing_analysis
    else:
        score -= 25
    
    # Filing Recency (15 points)
    if returns:
        latest_return_date = None
        for return_item in returns:
            if return_item.get("dof"):
                try:
                    filing_date = datetime.strptime(return_item["dof"], "%d/%m/%Y")
                    if latest_return_date is None or filing_date > latest_return_date:
                        latest_return_date = filing_date
                except:
                    continue
        
        if latest_return_date:
            current_date = datetime.now()
            days_since_filing = (current_date - latest_return_date).days
            if days_since_filing <= 30:
                recency_points = 15
            elif days_since_filing <= 60:
                recency_points = 10
            elif days_since_filing <= 90:
                recency_points = 5
            else:
                recency_points = 0
            
            score = score - 15 + recency_points
    else:
        score -= 15
    
    # Filing Frequency (5 points)
    filing_freq = company_data.get("fillingFreq", {})
    if filing_freq:
        monthly_count = sum(1 for freq in filing_freq.values() if freq == "M")
        quarterly_count = sum(1 for freq in filing_freq.values() if freq == "Q")
        
        if monthly_count >= 6:
            freq_points = 5
        elif quarterly_count >= 6:
            freq_points = 4
        else:
            freq_points = 2
        
        score = score - 5 + freq_points
    else:
        score -= 3
    
    # E-Invoice & Annual Returns (5 points each)
    einvoice = company_data.get("einvoiceStatus", "No")
    if einvoice != "Yes":
        score -= 3
    
    annual_returns = [r for r in returns if r.get("rtntype") == "GSTR9"]
    if not annual_returns:
        score -= 5
    
    final_score = max(0, min(100, score))
    logger.info(f"Calculated compliance score: {final_score} for company {company_data.get('lgnm', 'Unknown')}")
    return final_score

def check_password(password: str, stored_hash: str, salt: str) -> bool:
    hash_attempt = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000, dklen=64).hex()
    return hash_attempt == stored_hash

# Routes
@app.get("/health")
async def health_check():
    try:
        db_status = "healthy"
        try:
            await db.initialize()
            async with db.pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
        except Exception as e:
            db_status = f"unhealthy: {str(e)}"
        
        return {
            "status": "healthy" if db_status == "healthy" else "degraded",
            "timestamp": datetime.now().isoformat(),
            "version": "2.0.0",
            "checks": {
                "database": db_status,
                "gst_api": "configured" if RAPIDAPI_KEY else "missing",
                "ai_features": "configured" if ANTHROPIC_API_KEY else "disabled"
            }
        }
    except Exception as e:
        return JSONResponse(
            status_code=503,
            content={"status": "unhealthy", "error": str(e), "timestamp": datetime.now().isoformat()}
        )

# FIXED Routes for main.py - Replace existing routes

# REPLACE the dashboard route in main.py with this FIXED version

@app.get("/", response_class=HTMLResponse)
async def dashboard(request: Request, current_user: str = Depends(require_auth)):
    """Dashboard route - FINAL FIX with complete datetime handling"""
    try:
        await db.initialize()
        
        # Initialize default values
        user_stats = {
            "total_searches": 0,
            "unique_companies": 0, 
            "avg_compliance": 0.0,
            "searches_this_month": 0
        }
        history = []
        
        try:
            # Get user stats (this works fine)
            user_stats = await db.get_user_stats(current_user)
            logger.info(f"✅ Got user stats: {user_stats}")
            
            # Get search history with complete error handling
            try:
                history_raw = await db.get_search_history(current_user, 5)
                logger.info(f"✅ Got {len(history_raw)} raw history items")
                
                # Convert ALL objects to template-safe format
                history = []
                for item in history_raw:
                    try:
                        # Convert database row to dict
                        if hasattr(item, '_mapping'):
                            item_dict = dict(item)
                        else:
                            item_dict = item
                        
                        # Serialize all values to ensure no datetime issues
                        safe_item = serialize_for_template(item_dict)
                        
                        # Ensure required fields exist
                        safe_item.setdefault('company_name', 'Unknown Company')
                        safe_item.setdefault('compliance_score', 0)
                        safe_item.setdefault('ai_synopsis', '')
                        safe_item.setdefault('gstin', '')
                        
                        # Convert searched_at to a proper datetime object for template
                        if 'searched_at' in safe_item:
                            if isinstance(safe_item['searched_at'], str):
                                try:
                                    safe_item['searched_at'] = datetime.fromisoformat(safe_item['searched_at'].replace('Z', '+00:00'))
                                except:
                                    safe_item['searched_at'] = datetime.now()
                            elif not isinstance(safe_item['searched_at'], datetime):
                                safe_item['searched_at'] = datetime.now()
                        else:
                            safe_item['searched_at'] = datetime.now()
                        
                        history.append(safe_item)
                        
                    except Exception as item_error:
                        logger.error(f"⚠️ Error processing history item: {item_error}")
                        # Add a default item to prevent empty history
                        history.append({
                            'gstin': 'ERROR',
                            'company_name': 'Error loading data',
                            'compliance_score': 0,
                            'searched_at': datetime.now(),
                            'ai_synopsis': ''
                        })
                
                logger.info(f"✅ Processed {len(history)} history items safely")
                
            except Exception as hist_error:
                logger.error(f"⚠️ History loading failed: {hist_error}")
                history = []  # Continue with empty history
            
        except Exception as e:
            logger.error(f"⚠️ Error loading data for {current_user}: {e}")
            # Continue with default values
        
        # Ensure we have valid numbers - NO datetime objects here
        user_profile = {
            "total_searches": int(user_stats.get("total_searches", 0)),
            "unique_companies": int(user_stats.get("unique_companies", 0)),
            "avg_compliance": float(user_stats.get("avg_compliance", 0)),
            "searches_this_month": int(user_stats.get("searches_this_month", 0))
        }
        
        # Create profile data with NO datetime objects that could be serialized
        profile_data = {
            "user_info": {
                "mobile": current_user,
                "created_at": None,  # Don't include datetime objects here
                "email": None
            },
            "search_stats": user_profile,  # This is safe - only numbers
            "recent_searches": []  # Don't pass history here to avoid serialization issues
        }
        
        # Debug logging
        logger.info(f"✅ Dashboard rendering for {current_user}: stats={user_profile}, history_count={len(history)}")
        
        # Pass data to template - template can handle datetime objects in history
        return templates.TemplateResponse("index.html", {
            "request": request,
            "current_user": current_user,
            "user_display_name": current_user,
            "history": history,  # Template can handle datetime objects
            "user_profile": user_profile,  # Only numbers
            "searches_this_month": user_profile["searches_this_month"],
            "profile_data": profile_data  # No datetime objects here
        })
        
    except Exception as e:
        logger.error(f"❌ Dashboard critical error for {current_user}: {e}")
        
        # Return absolute minimal data to prevent any serialization issues
        minimal_profile = {
            "total_searches": 0,
            "unique_companies": 0,
            "avg_compliance": 0.0,
            "searches_this_month": 0
        }
        
        return templates.TemplateResponse("index.html", {
            "request": request,
            "current_user": current_user,
            "user_display_name": current_user,
            "history": [],
            "user_profile": minimal_profile,
            "searches_this_month": 0,
            "profile_data": {
                "user_info": {"mobile": current_user},
                "search_stats": minimal_profile,
                "recent_searches": []
            }
        })

@app.get("/login", response_class=HTMLResponse)
async def get_login(request: Request):
    return templates.TemplateResponse("login.html", {"request": request})

@app.post("/login")
async def post_login(request: Request, mobile: str = Form(...), password: str = Form(...)):
    form_data = {
        'mobile': mobile,
        'password': password
    }

    validation_rules = {
        'mobile': {'type': 'mobile', 'required': True},
        'password': {'type': 'text', 'required': True}
    }

    validation_result = EnhancedDataValidator.validate_form_data(form_data, validation_rules)

    if not validation_result['is_valid']:
        return templates.TemplateResponse("login.html", {
            "request": request,
            "error": list(validation_result['errors'].values())[0]
        })
    
    if not login_limiter.is_allowed(mobile):
        return templates.TemplateResponse("login.html", {
            "request": request, 
            "error": "Too many login attempts. Please try again later."
        })
    
    await db.initialize()
    if not await db.verify_user(mobile, password):
        return templates.TemplateResponse("login.html", {
            "request": request, 
            "error": "Invalid mobile number or password"
        })
    
    session_token = await db.create_session(mobile)
    await db.update_last_login(mobile)
    
    response = RedirectResponse(url="/", status_code=302)
    response.set_cookie(
        key="session_token", 
        value=session_token, 
        max_age=30*24*60*60,  # 30 days
        httponly=True,
        secure=False  # Set to True in production with HTTPS
    )
    return response

@app.get("/admin", response_class=HTMLResponse)
async def admin_dashboard_page(request: Request, current_user: str = Depends(require_auth)):
    return templates.TemplateResponse("admin_dashboard.html", {
        "request": request,
        "current_user": current_user
    })

@app.get("/api/admin/stats")
async def admin_stats(current_user: str = Depends(require_auth)):
    return JSONResponse({
        "success": True,
        "user_stats": {"total_users": 0, "active_users": 0},
        "search_stats": {"total_searches": 0, "searches_today": 0}
    })

@app.get("/api/admin/users")
async def admin_users(current_user: str = Depends(require_auth)):
    return JSONResponse({
        "success": True,
        "users": [],
        "pagination": {"page": 1, "pages": 1, "total": 0}
    })

@app.get("/api/admin/system/health")
async def system_health(current_user: str = Depends(require_auth)):
    return JSONResponse({
        "success": True,
        "health": {
            "database": "healthy",
            "api": "configured",
            "ai": "configured" if ANTHROPIC_API_KEY else "not configured"
        }
    })

@app.get("/signup", response_class=HTMLResponse)
async def get_signup(request: Request):
    return templates.TemplateResponse("signup.html", {"request": request})

@app.post("/signup")
async def post_signup(request: Request, mobile: str = Form(...), password: str = Form(...), confirm_password: str = Form(...)):
    form_data = {
        'mobile': mobile,
        'password': password,
        'confirm_password': confirm_password
    }

    validation_rules = {
        'mobile': {'type': 'mobile', 'required': True},
        'password': {'type': 'text', 'required': True},
        'confirm_password': {'type': 'text', 'required': True}
    }

    validation_result = EnhancedDataValidator.validate_form_data(form_data, validation_rules)

    if not validation_result['is_valid']:
        return templates.TemplateResponse("signup.html", {
            "request": request,
            "error": list(validation_result['errors'].values())[0]
        })
    
    if password != confirm_password:
        return templates.TemplateResponse("signup.html", {
            "request": request, 
            "error": "Passwords do not match"
        })
    
    if len(password) < 8:
        return templates.TemplateResponse("signup.html", {
            "request": request, 
            "error": "Password must be at least 8 characters long"
        })
    
    try:
        await db.initialize()
        salt = secrets.token_hex(16)
        password_hash = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt.encode('utf-8'), 100000, dklen=64).hex()
        
        success = await db.create_user(mobile, password_hash, salt)
        
        if success:
            return templates.TemplateResponse("signup.html", {
                "request": request, 
                "success": "Account created successfully! Please login."
            })
        else:
            return templates.TemplateResponse("signup.html", {
                "request": request, 
                "error": "Mobile number already exists"
            })
    except Exception as e:
        logger.error(f"Signup error: {e}")
        return templates.TemplateResponse("signup.html", {
            "request": request, 
            "error": "An error occurred during registration"
        })

@app.get("/logout")
async def logout(request: Request):
    session_token = request.cookies.get("session_token")
    if session_token:
        await db.delete_session(session_token)
    
    response = RedirectResponse(url="/login", status_code=302)
    response.delete_cookie("session_token")
    return response

# FIXED Search Routes - Replace in main.py

@app.get("/search")
async def search_gstin_get(request: Request, gstin: str = None, current_user: str = Depends(require_auth)):
    """Handle GET requests to /search with GSTIN parameter"""
    if gstin:
        logger.info(f"GET search request for GSTIN: {gstin}")
        return await process_search(request, gstin, current_user)
    
    # If no GSTIN provided, redirect to dashboard
    logger.warning("GET search request without GSTIN, redirecting to dashboard")
    return RedirectResponse(url="/", status_code=302)

@app.post("/search")
async def search_gstin_post(request: Request, gstin: str = Form(...), current_user: str = Depends(require_auth)):
    """Handle POST requests to /search with form data"""
    logger.info(f"POST search request for GSTIN: {gstin}")
    return await process_search(request, gstin, current_user)

async def process_search(request: Request, gstin: str, current_user: str):
    """Process search with enhanced error handling and debugging"""
    try:
        # Clean and validate GSTIN
        gstin = gstin.strip().upper()
        logger.info(f"🔍 Processing search for GSTIN: {gstin} by user: {current_user}")
        
        # Enhanced validation
        if not gstin:
            logger.error("Empty GSTIN provided")
            return await render_dashboard_with_error(request, current_user, "Please enter a GSTIN")
        
        if len(gstin) != 15:
            logger.error(f"Invalid GSTIN length: {len(gstin)}")
            return await render_dashboard_with_error(request, current_user, f"GSTIN must be 15 characters (received {len(gstin)})")
        
        # Basic format validation
        if not gstin.replace('0', '').replace('1', '').replace('2', '').replace('3', '').replace('4', '').replace('5', '').replace('6', '').replace('7', '').replace('8', '').replace('9', '').replace('A', '').replace('B', '').replace('C', '').replace('D', '').replace('E', '').replace('F', '').replace('G', '').replace('H', '').replace('I', '').replace('J', '').replace('K', '').replace('L', '').replace('M', '').replace('N', '').replace('O', '').replace('P', '').replace('Q', '').replace('R', '').replace('S', '').replace('T', '').replace('U', '').replace('V', '').replace('W', '').replace('X', '').replace('Y', '').replace('Z', '') == '':
            logger.info(f"GSTIN format appears valid: {gstin}")
        else:
            logger.error(f"GSTIN contains invalid characters: {gstin}")
            return await render_dashboard_with_error(request, current_user, "GSTIN contains invalid characters")
        
        # Rate limiting check
        if not api_limiter.is_allowed(current_user):
            logger.warning(f"Rate limit exceeded for user: {current_user}")
            return await render_dashboard_with_error(request, current_user, "Rate limit exceeded. Please try again later.")
        
        # API client check
        if not api_client:
            logger.error("GST API service not configured")
            return await render_dashboard_with_error(request, current_user, "GST API service not configured. Please contact administrator.")
        
        logger.info(f"🌐 Fetching data from GST API for: {gstin}")
        
        # Fetch company data
        try:
            company_data = await api_client.fetch_gstin_data(gstin)
            logger.info(f"✅ Successfully fetched company data for: {gstin}")
        except HTTPException as e:
            logger.error(f"HTTPException while fetching data: {e.detail}")
            if e.status_code == 404:
                return await render_dashboard_with_error(request, current_user, f"Company not found for GSTIN: {gstin}")
            else:
                return await render_dashboard_with_error(request, current_user, f"API Error: {e.detail}")
        except Exception as e:
            logger.error(f"Unexpected error while fetching data: {str(e)}")
            return await render_dashboard_with_error(request, current_user, "Failed to fetch company data. Please try again.")
        
        # Calculate compliance score
        try:
            compliance_score = calculate_compliance_score(company_data)
            logger.info(f"📊 Calculated compliance score: {compliance_score} for {gstin}")
        except Exception as e:
            logger.error(f"Error calculating compliance score: {e}")
            compliance_score = 50.0  # Default score
            logger.info(f"Using default compliance score: {compliance_score}")
        
        # Get AI synopsis
        synopsis = None
        try:
            logger.info("🤖 Attempting to generate AI synopsis...")
            synopsis = await get_enhanced_ai_synopsis(company_data)
            if synopsis:
                logger.info("✅ AI synopsis generated successfully")
            else:
                logger.warning("⚠️ AI synopsis returned None")
                synopsis = "AI analysis temporarily unavailable"
        except Exception as e:
            logger.error(f"❌ AI synopsis generation failed: {e}")
            synopsis = "AI analysis temporarily unavailable"
        
        # Add to search history
        try:
            await db.add_search_history(
                current_user, gstin, 
                company_data.get("lgnm", "Unknown"), 
                compliance_score, company_data, synopsis
            )
            logger.info(f"✅ Search history saved for {gstin}")
        except Exception as e:
            logger.error(f"Failed to save search history: {e}")
            # Don't fail the request for this
        
        # Get late filing analysis
        late_filing_analysis = company_data.get('_late_filing_analysis', {})
        
        logger.info(f"🎯 Rendering results page for {gstin}")
        
        # Render results page
        return templates.TemplateResponse("results.html", {
            "request": request,
            "current_user": current_user,
            "company_data": company_data,
            "compliance_score": compliance_score,
            "synopsis": synopsis,
            "late_filing_analysis": late_filing_analysis,
            "gstin": gstin
        })
        
    except Exception as e:
        logger.error(f"❌ Critical error in process_search: {str(e)}", exc_info=True)
        return await render_dashboard_with_error(request, current_user, "An unexpected error occurred. Please try again.")

async def render_dashboard_with_error(request: Request, current_user: str, error_message: str):
    """Helper function to render dashboard with error message"""
    try:
        # Get user profile data for dashboard
        await db.initialize()
        user_stats = await db.get_user_stats(current_user)
        history = await db.get_search_history(current_user, 5)
        
        # Convert history to template-safe format
        safe_history = []
        for item in history:
            safe_item = serialize_for_template(item)
            safe_history.append(safe_item)
        
        return templates.TemplateResponse("index.html", {
            "request": request, 
            "current_user": current_user,
            "user_display_name": current_user,
            "error": error_message,
            "history": safe_history,
            "user_profile": user_stats,
            "searches_this_month": user_stats.get("searches_this_month", 0),
            "profile_data": {
                "user_info": {"mobile": current_user, "created_at": None, "email": None},
                "search_stats": user_stats,
                "recent_searches": []
            }
        })
    except Exception as e:
        logger.error(f"Error rendering dashboard with error: {e}")
        # Fallback error response
        return templates.TemplateResponse("index.html", {
            "request": request,
            "current_user": current_user,  
            "user_display_name": current_user,
            "error": error_message,
            "history": [],
            "user_profile": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0},
            "searches_this_month": 0,
            "profile_data": {
                "user_info": {"mobile": current_user},
                "search_stats": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0},
                "recent_searches": []
            }
        })

@app.get("/history", response_class=HTMLResponse)
async def view_history(request: Request, current_user: str = Depends(require_auth)):
    await db.initialize()
    history = await db.get_all_searches(current_user)
    
    # Calculate statistics
    total_searches = len(history)
    unique_companies = len(set(item["gstin"] for item in history)) if history else 0
    avg_compliance = sum(item["compliance_score"] or 0 for item in history) / total_searches if total_searches > 0 else 0
    
    return templates.TemplateResponse("history.html", {
        "request": request,
        "current_user": current_user,
        "history": history,
        "total_searches": total_searches,
        "unique_companies": unique_companies,
        "avg_compliance": round(avg_compliance, 1)
    })

@app.get("/api/search/suggestions")
async def search_suggestions(q: str, current_user: str = Depends(require_auth)):
    if len(q) < 3:
        return JSONResponse({"suggestions": []})
    
    await db.initialize()
    async with db.pool.acquire() as conn:
        suggestions = await conn.fetch("""
            SELECT DISTINCT gstin, company_name 
            FROM search_history 
            WHERE mobile = $1 AND (gstin ILIKE $2 OR company_name ILIKE $2)
            ORDER BY searched_at DESC LIMIT 5
        """, current_user, f"%{q}%")
    
    return JSONResponse({
        "suggestions": [{"gstin": row["gstin"], "company_name": row["company_name"]} for row in suggestions]
    })

@app.get("/analytics", response_class=HTMLResponse)
async def analytics_dashboard(request: Request, current_user: str = Depends(require_auth)):
    await db.initialize()
    
    # Get analytics data with better error handling
    try:
        async with db.pool.acquire() as conn:
            # Get daily searches for the last 7 days
            daily_searches = await conn.fetch("""
                SELECT DATE(searched_at) as date, COUNT(*) as search_count, AVG(compliance_score) as avg_score
                FROM search_history WHERE mobile = $1 AND searched_at >= CURRENT_DATE - INTERVAL '7 days'
                GROUP BY DATE(searched_at) ORDER BY date
            """, current_user)
            
            # Get compliance score distribution
            score_distribution = await conn.fetch("""
                SELECT 
                    CASE 
                        WHEN compliance_score >= 90 THEN 'Excellent (90-100)'
                        WHEN compliance_score >= 80 THEN 'Very Good (80-89)'
                        WHEN compliance_score >= 70 THEN 'Good (70-79)'
                        WHEN compliance_score >= 60 THEN 'Average (60-69)'
                        ELSE 'Poor (<60)' 
                    END as range, 
                    COUNT(*) as count
                FROM search_history 
                WHERE mobile = $1 AND compliance_score IS NOT NULL 
                GROUP BY 
                    CASE 
                        WHEN compliance_score >= 90 THEN 'Excellent (90-100)'
                        WHEN compliance_score >= 80 THEN 'Very Good (80-89)'
                        WHEN compliance_score >= 70 THEN 'Good (70-79)'
                        WHEN compliance_score >= 60 THEN 'Average (60-69)'
                        ELSE 'Poor (<60)' 
                    END 
                ORDER BY MIN(compliance_score) DESC
            """, current_user)
            
            # Get top searched companies
            top_companies = await conn.fetch("""
                SELECT company_name, gstin, COUNT(*) as search_count, MAX(compliance_score) as latest_score
                FROM search_history WHERE mobile = $1 
                GROUP BY company_name, gstin
                ORDER BY search_count DESC LIMIT 10
            """, current_user)
            
            # Get user stats
            user_stats = await db.get_user_stats(current_user)
    except Exception as e:
        logger.error(f"Analytics data error: {e}")
        daily_searches = []
        score_distribution = []
        top_companies = []
        user_stats = {"total_searches": 0, "unique_companies": 0, "avg_compliance": 0, "searches_this_month": 0}
    
    # Convert dates for JSON serialization
    daily_searches_json = []
    for row in daily_searches:
        daily_searches_json.append({
            "date": row["date"].isoformat() if hasattr(row["date"], "isoformat") else str(row["date"]),
            "search_count": int(row["search_count"]) if row["search_count"] else 0,
            "avg_score": float(row["avg_score"]) if row["avg_score"] else 0
        })
    
    return templates.TemplateResponse("analytics.html", {
        "request": request, 
        "current_user": current_user, 
        "daily_searches": daily_searches_json,
        "score_distribution": [dict(row) for row in score_distribution],
        "top_companies": [dict(row) for row in top_companies],
        "total_searches": user_stats.get("total_searches", 0), 
        "unique_companies": user_stats.get("unique_companies", 0),
        "avg_compliance": round(user_stats.get("avg_compliance", 0), 1),
        "searches_this_month": user_stats.get("searches_this_month", 0)
    })

@app.get("/api/analytics/dashboard")
async def analytics_api(current_user: str = Depends(require_auth)):
    await db.initialize()
    async with db.pool.acquire() as conn:
        recent_searches = await conn.fetch("""
            SELECT gstin, company_name, compliance_score, searched_at
            FROM search_history WHERE mobile = $1 
            ORDER BY searched_at DESC LIMIT 5
        """, current_user)
    
    return JSONResponse({
        "success": True,
        "data": {
            "recent_searches": [dict(row) for row in recent_searches]
        }
    })

@app.get("/profile", response_class=HTMLResponse)
async def profile_page(request: Request, current_user: str = Depends(require_auth)):
    """User profile page - FIXED"""
    try:
        await db.initialize()
        profile_data = await db.get_user_profile_data(current_user)
        
        # Fix datetime formatting safely
        if profile_data.get("user_info") and profile_data["user_info"].get("created_at"):
            created_at = profile_data["user_info"]["created_at"]
            if hasattr(created_at, 'strftime'):
                profile_data["user_info"]["created_at_formatted"] = created_at.strftime('%Y-%m-%d')
            else:
                profile_data["user_info"]["created_at_formatted"] = str(created_at)[:10]
        
        return templates.TemplateResponse("profile.html", {
            "request": request,
            "current_user": current_user,
            "profile_data": profile_data,
            "user_display_name": current_user
        })
        
    except Exception as e:
        logger.error(f"Profile page error: {e}")
        return templates.TemplateResponse("profile.html", {
            "request": request,
            "current_user": current_user,
            "profile_data": {
                "user_info": {"mobile": current_user},
                "search_stats": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0},
                "recent_searches": []
            },
            "user_display_name": current_user
        })

@app.get("/privacy", response_class=HTMLResponse)
async def privacy_page(request: Request, current_user: Optional[str] = Depends(get_current_user)):
    return HTMLResponse("""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Privacy Policy - GST Intelligence Platform</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="/static/css/base.css">
    </head>
    <body>
        <div style="max-width: 800px; margin: 2rem auto; padding: 2rem; background: var(--bg-card); border-radius: 16px;">
            <h1>Privacy Policy</h1>
            <p>Your privacy is important to us. This policy explains how we collect, use, and protect your information.</p>
            <h2>Information We Collect</h2>
            <p>We collect only the information necessary to provide our GST compliance services.</p>
            <h2>How We Use Your Information</h2>
            <p>We use your information solely for providing GST analysis and compliance services.</p>
            <p><a href="/">← Back to Dashboard</a></p>
        </div>
    </body>
    </html>
    """)

@app.get("/terms", response_class=HTMLResponse)
async def terms_page(request: Request, current_user: Optional[str] = Depends(get_current_user)):
    return HTMLResponse("""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Terms of Service - GST Intelligence Platform</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="/static/css/base.css">
    </head>
    <body>
        <div style="max-width: 800px; margin: 2rem auto; padding: 2rem; background: var(--bg-card); border-radius: 16px;">
            <h1>Terms of Service</h1>
            <p>Welcome to GST Intelligence Platform. By using our service, you agree to these terms.</p>
            <h2>Service Description</h2>
            <p>We provide GST compliance analysis and business intelligence services.</p>
            <h2>User Responsibilities</h2>
            <p>Users are responsible for providing accurate information and using the service appropriately.</p>
            <p><a href="/">← Back to Dashboard</a></p>
        </div>
    </body>
    </html>
    """)

@app.get("/help", response_class=HTMLResponse)
async def help_page(request: Request, current_user: Optional[str] = Depends(get_current_user)):
    return templates.TemplateResponse("contact.html", {
        "request": request,
        "current_user": current_user
    })

@app.get("/settings", response_class=HTMLResponse)
async def settings_page(request: Request, current_user: str = Depends(require_auth)):
    return templates.TemplateResponse("profile.html", {
        "request": request,
        "current_user": current_user,
        "user_display_name": current_user
    })

@app.get("/static/icons/icon-144x144.png")
async def icon_fallback():
    """Fallback for missing icon"""
    try:
        return FileResponse("static/icons/favicon.png", media_type="image/png")
    except:
        from fastapi.responses import Response
        import base64
        transparent_png = base64.b64decode('iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==')
        return Response(content=transparent_png, media_type="image/png")

@app.get("/favicon.ico")
async def favicon():
    return FileResponse("static/icons/favicon.png", media_type="image/png")

@app.get("/manifest.json")
async def manifest():
    return FileResponse("static/manifest.json", media_type="application/json")

@app.get("/sw.js")
async def service_worker():
    return FileResponse("sw.js", media_type="application/javascript")

@app.get("/loans", response_class=HTMLResponse)
async def loans_page(request: Request, current_user: str = Depends(require_auth)):
    """Loan management page"""
    await db.initialize()
    
    # Sample loan configuration
    loan_config = {
        "min_amount": 50000,
        "max_amount": 5000000,
        "min_annual_turnover": 100000,
        "min_vintage": 6
    }
    
    return templates.TemplateResponse("loans.html", {
        "request": request,
        "current_user": current_user,
        "applications": [],  # Would fetch from loans table
        "loan_config": loan_config
    })

@app.get("/api/loans/eligibility")
async def check_loan_eligibility(
    gstin: str,
    annual_turnover: float,
    compliance_score: float,
    business_vintage_months: int,
    current_user: str = Depends(require_auth)
):
    try:
        eligible = True
        reasons = []
        
        if compliance_score < 60:
            eligible = False
            reasons.append("Compliance score must be at least 60%")
        
        if annual_turnover < 100000:
            eligible = False
            reasons.append("Annual turnover must be at least ₹1,00,000")
        
        if business_vintage_months < 6:
            eligible = False
            reasons.append("Business must be at least 6 months old")
        
        max_loan_amount = min(annual_turnover * 0.5, 5000000)
        recommended_amount = max_loan_amount * 0.7
        
        return JSONResponse({
            "success": True,
            "data": {
                "eligible": eligible,
                "reasons": reasons,
                "max_loan_amount": max_loan_amount,
                "recommended_amount": recommended_amount
            }
        })
        
    except Exception as e:
        logger.error(f"Loan eligibility error: {e}")
        return JSONResponse({"success": False, "error": "Failed to check eligibility"})

@app.post("/api/loans/apply")
async def apply_for_loan(request: Request, current_user: str = Depends(require_auth)):
    try:
        data = await request.json()
        logger.info(f"Loan application from {current_user}: {data}")
        
        return JSONResponse({
            "success": True,
            "message": "Loan application submitted successfully",
            "application_id": "LA" + str(int(datetime.now().timestamp()))
        })
        
    except Exception as e:
        logger.error(f"Loan application error: {e}")
        return JSONResponse({"success": False, "error": "Failed to submit application"})

@app.get("/api/loans/applications")
async def get_loan_applications(current_user: str = Depends(require_auth)):
    try:
        return JSONResponse({
            "success": True,
            "data": []
        })
    except Exception as e:
        logger.error(f"Get loan applications error: {e}")
        return JSONResponse({"success": False, "error": "Failed to fetch applications"})

@app.get("/contact", response_class=HTMLResponse)
async def contact_get(request: Request, current_user: Optional[str] = Depends(get_current_user)):
    """Contact page"""
    return templates.TemplateResponse("contact.html", {
        "request": request,
        "current_user": current_user
    })

@app.post("/contact")
async def contact_post(
    request: Request,
    name: str = Form(...),
    email: str = Form(...),
    subject: str = Form(...),
    message: str = Form(...),
    current_user: Optional[str] = Depends(get_current_user)
):
    try:
        # Validate form data
        form_data = {
            'name': name,
            'email': email,
            'subject': subject,
            'message': message
        }
        
        validation_rules = {
            'name': {'type': 'text', 'required': True},
            'email': {'type': 'email', 'required': True},
            'subject': {'type': 'text', 'required': True},
            'message': {'type': 'text', 'required': True}
        }
        
        validation_result = EnhancedDataValidator.validate_form_data(form_data, validation_rules)
        
        if not validation_result['is_valid']:
            return templates.TemplateResponse("contact.html", {
                "request": request,
                "current_user": current_user,
                "error_message": list(validation_result['errors'].values())[0]
            })
        
        # Log contact submission
        cleaned_data = validation_result['cleaned_data']
        logger.info(f"Contact form submitted by {cleaned_data['name']} ({cleaned_data['email']}): {cleaned_data['subject']}")
        
        return templates.TemplateResponse("contact.html", {
            "request": request,
            "current_user": current_user,
            "success_message": "Thank you for your message. We'll get back to you soon!"
        })
        
    except Exception as e:
        logger.error(f"Contact form error: {e}")
        return templates.TemplateResponse("contact.html", {
            "request": request,
            "current_user": current_user,
            "error_message": "Failed to send message. Please try again."
        })

# API Endpoints
@app.post("/api/search")
async def api_search(request: Request, gstin: str = Form(...), current_user: str = Depends(require_auth)):
    """API endpoint for search functionality"""
    try:
        # Validate GSTIN
        if not validate_gstin(gstin):
            return JSONResponse({"success": False, "error": "Invalid GSTIN format"})
        
        # Check rate limit
        if not api_limiter.is_allowed(current_user):
            return JSONResponse({"success": False, "error": "Rate limit exceeded"})
        
        if not api_client:
            return JSONResponse({"success": False, "error": "GST API service not configured"})
            
        # Fetch company data
        company_data = await api_client.fetch_gstin_data(gstin)
        compliance_score = calculate_compliance_score(company_data)
        
        # Get AI synopsis
        synopsis = None
        if ANTHROPIC_API_KEY:
            try:
                synopsis = await get_anthropic_synopsis(company_data)
            except Exception as e:
                logger.error(f"Failed to get AI synopsis: {e}")
        
        # Add to search history
        await db.add_search_history(
            current_user, gstin, 
            company_data.get("lgnm", "Unknown"), 
            compliance_score, company_data, synopsis
        )
        
        return JSONResponse({
            "success": True,
            "data": {
                "gstin": gstin,
                "legal_name": company_data.get("lgnm"),
                "trade_name": company_data.get("tradeNam"),
                "business_status": company_data.get("sts"),
                "filing_status": company_data.get("fillingFreq", {}).get("status", "Unknown"),
                "registration_date": company_data.get("rgdt"),
                "compliance_score": compliance_score,
                "ai_synopsis": synopsis
            }
        })
    except Exception as e:
        logger.error(f"API search error: {e}")
        return JSONResponse({"success": False, "error": str(e)})

@app.get("/api/user/stats")
async def get_user_stats_api(current_user: str = Depends(require_auth)):
    """Get user statistics - DATETIME FIXED"""
    try:
        await db.initialize()
        stats = await db.get_user_stats(current_user)
        
        # Calculate user level
        total_searches = stats.get("total_searches", 0)
        
        if total_searches >= 100:
            user_level = {"level": "Expert", "icon": "fas fa-crown", "color": "#f59e0b"}
        elif total_searches >= 50:
            user_level = {"level": "Advanced", "icon": "fas fa-star", "color": "#8b5cf6"}
        elif total_searches >= 20:
            user_level = {"level": "Intermediate", "icon": "fas fa-user-graduate", "color": "#06b6d4"}
        elif total_searches >= 5:
            user_level = {"level": "Beginner", "icon": "fas fa-seedling", "color": "#10b981"}
        else:
            user_level = {"level": "New User", "icon": "fas fa-user-plus", "color": "#6b7280"}
        
        # Ensure all data is JSON serializable
        response_data = {
            "total_searches": int(stats.get("total_searches", 0)),
            "avg_compliance": float(stats.get("avg_compliance", 0)),
            "unique_companies": int(stats.get("unique_companies", 0)),
            "searches_this_month": int(stats.get("searches_this_month", 0)),
            "user_level": user_level
        }
        
        return safe_json_response({
            "success": True,
            "data": response_data
        })
        
    except Exception as e:
        logger.error(f"User stats API error: {e}")
        return safe_json_response({
            "success": False,
            "error": str(e),
            "data": {
                "total_searches": 0,
                "avg_compliance": 0.0,
                "unique_companies": 0,
                "searches_this_month": 0,
                "user_level": {"level": "New User", "icon": "fas fa-user", "color": "#6b7280"}
            }
        })

@app.get("/api/user/export")
async def export_user_data(current_user: str = Depends(require_auth)):
    """Export user data as JSON"""
    try:
        await db.initialize()
        
        # Get all user data
        profile_data = await db.get_user_profile_data(current_user)
        all_searches = await db.get_all_searches(current_user)
        
        export_data = {
            "export_date": datetime.now().isoformat(),
            "user_mobile": current_user,
            "profile": profile_data["user_info"],
            "statistics": profile_data["search_stats"],
            "search_history": all_searches,
            "total_records": len(all_searches)
        }
        
        # Convert to JSON
        json_data = json.dumps(export_data, indent=2, default=str)
        
        return StreamingResponse(
            BytesIO(json_data.encode()),
            media_type="application/json",
            headers={
                "Content-Disposition": f"attachment; filename=profile_data_{current_user}_{datetime.now().strftime('%Y%m%d')}.json"
            }
        )
        
    except Exception as e:
        logger.error(f"Export error: {e}")
        raise HTTPException(status_code=500, detail="Failed to export data")

@app.get("/api/user/activity")
async def get_user_activity(days: int = 30, current_user: str = Depends(require_auth)):
    """Get user activity data - DATETIME SAFE"""
    try:
        # Return simple mock data for now to avoid datetime issues
        return safe_json_response({
            "success": True,
            "data": {
                "daily_activity": [
                    {"date": "2024-07-20", "searches": 2},
                    {"date": "2024-07-21", "searches": 1},
                    {"date": "2024-07-22", "searches": 3},
                    {"date": "2024-07-23", "searches": 2},
                    {"date": "2024-07-24", "searches": 1}
                ],
                "hourly_activity": [
                    {"hour": 9, "searches": 2},
                    {"hour": 14, "searches": 3},
                    {"hour": 16, "searches": 1}
                ]
            }
        })
    except Exception as e:
        logger.error(f"User activity error: {e}")
        return safe_json_response({
            "success": False,
            "error": str(e)
        })

@app.get("/api/user/preferences")
async def get_user_preferences(current_user: str = Depends(require_auth)):
    """Get user preferences - DATETIME SAFE"""
    return safe_json_response({
        "success": True,
        "data": {
            "theme": "dark",
            "compactMode": False
        }
    })

@app.get("/api/user/profile")
async def user_profile(current_user: str = Depends(require_auth)):
    await db.initialize()
    async with db.pool.acquire() as conn:
        user_data = await conn.fetchrow("SELECT * FROM users WHERE mobile = $1", current_user)
        search_count = await conn.fetchval("SELECT COUNT(*) FROM search_history WHERE mobile = $1", current_user)
    
    return JSONResponse({
        "success": True,
        "data": {
            "mobile": current_user,
            "created_at": user_data["created_at"].isoformat() if user_data and user_data["created_at"] else None,
            "last_login": user_data["last_login"].isoformat() if user_data and user_data["last_login"] else None,
            "search_count": search_count
        }
    })

@app.post("/api/user/profile")
async def update_user_profile(
    request: Request,
    display_name: str = Form(None),
    email: str = Form(None),
    company: str = Form(None),
    current_user: str = Depends(require_auth)
):
    try:
        await db.initialize()
        # Update logic here
        return JSONResponse({"success": True, "message": "Profile updated successfully"})
    except Exception as e:
        logger.error(f"Profile update error: {e}")
        return JSONResponse({"success": False, "error": "Failed to update profile"})
    
@app.get("/export/history")
async def export_history(current_user: str = Depends(require_auth)):
    """Export search history as CSV"""
    try:
        await db.initialize()
        history = await db.get_all_searches(current_user)
        
        output = StringIO()
        writer = csv.DictWriter(output, fieldnames=['searched_at', 'gstin', 'company_name', 'compliance_score'])
        writer.writeheader()
        
        # Convert datetime objects to strings for CSV
        for row in history:
            if row.get('searched_at'):
                row['searched_at'] = row['searched_at'].isoformat()
            writer.writerow(row)
        
        content = output.getvalue()
        output.close()
        
        return StreamingResponse(
            BytesIO(content.encode()), 
            media_type="text/csv",
            headers={"Content-Disposition": f"attachment; filename=gst_search_history_{datetime.now().strftime('%Y%m%d')}.csv"}
        )
    except Exception as e:
        logger.error(f"Export history error: {e}")
        raise HTTPException(status_code=500, detail="Failed to export history")

@app.post("/change-password")
async def change_password_route(
    request: Request,
    current_password: str = Form(...),
    new_password: str = Form(...),
    confirm_password: str = Form(...),
    current_user: str = Depends(require_auth)
):
    """Change user password"""
    try:
        if new_password != confirm_password:
            return JSONResponse({"success": False, "error": "Passwords do not match"})
        
        if len(new_password) < 8:
            return JSONResponse({"success": False, "error": "Password must be at least 8 characters"})
        
        await db.initialize()
        async with db.pool.acquire() as conn:
            # Get current user data
            user_data = await conn.fetchrow("SELECT password_hash, salt FROM users WHERE mobile = $1", current_user)
            
            if not user_data:
                return JSONResponse({"success": False, "error": "User not found"})
            
            # Verify current password
            if not check_password(current_password, user_data["password_hash"], user_data["salt"]):
                return JSONResponse({"success": False, "error": "Current password is incorrect"})
            
            # Generate new password hash
            new_salt = secrets.token_hex(16)
            new_hash = hashlib.pbkdf2_hmac('sha256', new_password.encode('utf-8'), new_salt.encode('utf-8'), 100000, dklen=64).hex()
            
            # Update password
            await conn.execute(
                "UPDATE users SET password_hash = $1, salt = $2 WHERE mobile = $3",
                new_hash, new_salt, current_user
            )
            
            return JSONResponse({"success": True, "message": "Password updated successfully"})
            
    except Exception as e:
        logger.error(f"Password change error: {e}")
        return JSONResponse({"success": False, "error": "Failed to update password"})

# PDF generation
@app.post("/generate-pdf")
async def generate_pdf(request: Request, gstin: str = Form(...), current_user: str = Depends(require_auth)):
    try:
        if not api_client:
            raise HTTPException(status_code=503, detail="GST API service not configured")
            
        company_data = await api_client.fetch_gstin_data(gstin)
        compliance_score = calculate_compliance_score(company_data)
        
        synopsis = None
        if ANTHROPIC_API_KEY:
            try:
                synopsis = await get_anthropic_synopsis(company_data)
            except:
                synopsis = "AI synopsis not available"
        
        late_filing_analysis = company_data.get('_late_filing_analysis', None)
        pdf_content = generate_pdf_report(company_data, compliance_score, synopsis, late_filing_analysis)
        
        return StreamingResponse(
            pdf_content, media_type="application/pdf",
            headers={"Content-Disposition": f"attachment; filename=GST_Report_{gstin}.pdf"}
        )
        
    except Exception as e:
        logger.error(f"PDF generation error: {e}")
        raise HTTPException(status_code=500, detail="Failed to generate PDF")

def generate_pdf_report(company_data: dict, compliance_score: float, synopsis: str = None, late_filing_analysis: dict = None) -> BytesIO:
    if not WEASYPRINT_AVAILABLE:
        raise HTTPException(status_code=503, detail="PDF generation not available")
    
    company_name = company_data.get("lgnm", "Unknown Company")
    gstin = company_data.get("gstin", "N/A")
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            .header {{ background: #7c3aed; color: white; padding: 20px; text-align: center; }}
            .content {{ margin: 20px 0; }}
            .score {{ font-size: 24px; font-weight: bold; text-align: center; margin: 20px 0; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>GST Compliance Report</h1>
            <p>Generated on {datetime.now().strftime("%d %B %Y")}</p>
        </div>
        <div class="content">
            <h2>{company_name}</h2>
            <p>GSTIN: {gstin}</p>
            <div class="score">Compliance Score: {int(compliance_score)}%</div>
            {f'<div><h3>AI Synopsis</h3><p>{synopsis}</p></div>' if synopsis else ''}
        </div>
    </body>
    </html>
    """
    
    pdf_file = BytesIO()
    HTML(string=html_content).write_pdf(target=pdf_file)
    pdf_file.seek(0)
    return pdf_file

# Utility functions
def get_user_level(total_searches: int) -> dict:
    """Determine user level based on activity"""
    if total_searches >= 100:
        return {"level": "Expert", "icon": "fas fa-crown", "color": "#f59e0b"}
    elif total_searches >= 50:
        return {"level": "Advanced", "icon": "fas fa-star", "color": "#8b5cf6"}
    elif total_searches >= 20:
        return {"level": "Intermediate", "icon": "fas fa-user-graduate", "color": "#06b6d4"}
    elif total_searches >= 5:
        return {"level": "Beginner", "icon": "fas fa-seedling", "color": "#10b981"}
    else:
        return {"level": "New User", "icon": "fas fa-user-plus", "color": "#6b7280"}

def get_user_achievements(total_searches: int, avg_compliance: float) -> list:
    """Get user achievements based on activity"""
    achievements = []
    
    if total_searches >= 1:
        achievements.append({
            "title": "First Search", "icon": "fas fa-search", 
            "unlocked": True, "description": "Completed your first GST search"
        })
    
    if total_searches >= 10:
        achievements.append({
            "title": "Search Explorer", "icon": "fas fa-compass", 
            "unlocked": True, "description": "Completed 10 searches"
        })
    
    if total_searches >= 50:
        achievements.append({
            "title": "Power User", "icon": "fas fa-bolt", 
            "unlocked": True, "description": "Completed 50 searches"
        })
    
    if avg_compliance >= 80:
        achievements.append({
            "title": "Quality Seeker", "icon": "fas fa-trophy", 
            "unlocked": True, "description": "Average compliance score above 80%"
        })
    
    return achievements

async def process_search(request: Request, gstin: str, current_user: str):
    """Process search with proper compliance score calculation - FIXED"""
    gstin = gstin.strip().upper()
    is_valid, error_message = EnhancedDataValidator.validate_gstin(gstin)
    if not is_valid:
        return templates.TemplateResponse("index.html", {
            "request": request, 
            "current_user": current_user,
            "error": error_message,
            "user_profile": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0}
        })
    
    if not api_limiter.is_allowed(current_user):
        return templates.TemplateResponse("index.html", {
            "request": request, 
            "current_user": current_user,
            "error": "Rate limit exceeded. Please try again later.",
            "user_profile": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0}
        })
    
    if not api_client:
        return templates.TemplateResponse("index.html", {
            "request": request, 
            "current_user": current_user,
            "error": "GST API service not configured. Please contact administrator.",
            "user_profile": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0}
        })
    
    try:
        # Fetch company data
        company_data = await api_client.fetch_gstin_data(gstin)
        
        # Calculate compliance score with error handling
        try:
            compliance_score = calculate_compliance_score(company_data)
            logger.info(f"Calculated compliance score: {compliance_score} for {gstin}")
        except Exception as e:
            logger.error(f"Error calculating compliance score: {e}")
            compliance_score = 50.0  # Default score
        
        # Get AI synopsis
        synopsis = None
        try:
            logger.info("🤖 Attempting to generate AI synopsis...")
            synopsis = await get_enhanced_ai_synopsis(company_data)
            if synopsis:
                logger.info("✅ AI synopsis generated successfully")
            else:
                logger.warning("⚠️ AI synopsis returned None")
        except Exception as e:
            logger.error(f"❌ AI synopsis generation failed: {e}")
            synopsis = "AI analysis temporarily unavailable"
        
        # Add to search history with error handling
        try:
            await db.add_search_history(
                current_user, gstin, 
                company_data.get("lgnm", "Unknown"), 
                compliance_score, company_data, synopsis
            )
            logger.info(f"✅ Search history saved for {gstin}")
        except Exception as e:
            logger.error(f"Failed to save search history: {e}")
        
        # Get late filing analysis
        late_filing_analysis = company_data.get('_late_filing_analysis', {})
        
        return templates.TemplateResponse("results.html", {
            "request": request,
            "current_user": current_user,
            "company_data": company_data,
            "compliance_score": compliance_score,
            "synopsis": synopsis,
            "late_filing_analysis": late_filing_analysis,
            "gstin": gstin
        })
        
    except HTTPException as e:
        return templates.TemplateResponse("index.html", {
            "request": request, 
            "current_user": current_user,
            "error": f"Company not found for GSTIN: {gstin}",
            "user_profile": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0}
        })
    except Exception as e:
        logger.error(f"Search error: {e}")
        return templates.TemplateResponse("index.html", {
            "request": request, 
            "current_user": current_user,
            "error": "An error occurred while fetching data. Please try again.",
            "user_profile": {"total_searches": 0, "avg_compliance": 0, "unique_companies": 0, "searches_this_month": 0}
        })

# DEBUG ENDPOINTS - Add these before error handlers
@app.get("/debug/api-status")
async def debug_api_status_endpoint(current_user: str = Depends(require_auth)):
    """Debug endpoint to check API status"""
    try:
        if ENHANCED_APIS_AVAILABLE:
            results = await debug_api_status()
            return JSONResponse({
                "success": True,
                "debug_info": results,
                "enhanced_apis": True
            })
        else:
            # Basic check for original implementation
            return JSONResponse({
                "success": True,
                "debug_info": {
                    "environment": {
                        "rapidapi_key_set": bool(RAPIDAPI_KEY),
                        "anthropic_key_set": bool(ANTHROPIC_API_KEY),
                        "rapidapi_host": RAPIDAPI_HOST or "not set"
                    },
                    "gst_api": {"success": bool(api_client), "message": "Using original client"},
                    "anthropic_api": {"success": bool(ANTHROPIC_API_KEY), "message": "Using original client"}
                },
                "enhanced_apis": False,
                "recommendation": "Create api_debug_fix.py for enhanced debugging"
            })
    except Exception as e:
        logger.error(f"Debug endpoint error: {e}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

@app.post("/debug/test-gst-api")
async def test_gst_api_endpoint(
    gstin: str = Form(...), 
    current_user: str = Depends(require_auth)
):
    """Test GST API with a specific GSTIN"""
    try:
        if not api_client:
            return JSONResponse({
                "success": False,
                "error": "GST API client not configured"
            })
        
        logger.info(f"Testing GST API with GSTIN: {gstin}")
        company_data = await api_client.fetch_gstin_data(gstin)
        
        return JSONResponse({
            "success": True,
            "message": "GST API test successful",
            "data": {
                "gstin": gstin,
                "company_name": company_data.get("lgnm", "Unknown"),
                "status": company_data.get("sts", "Unknown"),
                "data_keys": list(company_data.keys())
            }
        })
        
    except Exception as e:
        logger.error(f"GST API test error: {e}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

@app.post("/debug/test-ai-synopsis")
async def test_ai_synopsis_endpoint(current_user: str = Depends(require_auth)):
    """Test AI synopsis generation"""
    try:
        # Sample company data for testing
        test_company_data = {
            "lgnm": "Test Company Pvt Ltd",
            "sts": "Active", 
            "rgdt": "01/01/2020",
            "gstin": "29AAAPL2356Q1ZS"
        }
        
        synopsis = await get_enhanced_ai_synopsis(test_company_data)
        
        return JSONResponse({
            "success": True,
            "message": "AI synopsis test completed",
            "data": {
                "synopsis": synopsis,
                "test_data": test_company_data
            }
        })
        
    except Exception as e:
        logger.error(f"AI synopsis test error: {e}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        })
    
# Error handlers
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    if exc.status_code == 303 and exc.headers and "Location" in exc.headers:
        return RedirectResponse(url=exc.headers["Location"], status_code=303)
    return JSONResponse(status_code=exc.status_code, content={"error": exc.detail})

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(status_code=500, content={"error": "An internal error occurred"})

@app.post("/api/system/log-error")
async def log_error(request: Request, current_user: str = Depends(require_auth)):
    try:
        data = await request.json()
        logger.error(f"Client error from {current_user}: {data}")
        return JSONResponse({"success": True})
    except Exception as e:
        logger.error(f"Error logging client error: {e}")
        return JSONResponse({"success": False})
    
@app.post("/api/system/error")
async def log_client_error(request: Request):
    """Handle client-side error logging"""
    try:
        data = await request.json()
        logger.warning(f"Client error: {data}")
        return JSONResponse({"success": True})
    except:
        return JSONResponse({"success": False})

@app.get("/debug/profile")
async def debug_profile(current_user: str = Depends(require_auth)):
    try:
        await db.initialize()
        profile_data = await db.get_user_profile_data(current_user)
        return JSONResponse({"profile_data": profile_data})
    except Exception as e:
        return JSONResponse({"error": str(e)})

@app.get("/api/debug/user-data")
async def debug_user_data(current_user: str = Depends(require_auth)):
    """Debug endpoint to check user data - FIXED datetime serialization"""
    try:
        await db.initialize()
        
        # Check if user exists
        async with db.pool.acquire() as conn:
            user_exists = await conn.fetchrow("SELECT mobile FROM users WHERE mobile = $1", current_user)
            
            # Check search history count
            search_count = await conn.fetchval("SELECT COUNT(*) FROM search_history WHERE mobile = $1", current_user)
            
            # Get sample search data with safe datetime handling
            sample_searches_raw = await conn.fetch("SELECT * FROM search_history WHERE mobile = $1 LIMIT 3", current_user)
            
            # Convert datetime objects to strings for JSON serialization
            sample_searches = []
            for row in sample_searches_raw:
                row_dict = dict(row)
                # Convert datetime to string
                for key, value in row_dict.items():
                    if hasattr(value, 'strftime'):  # It's a datetime object
                        row_dict[key] = value.isoformat()
                    elif hasattr(value, 'isoformat'):  # It's a date object
                        row_dict[key] = value.isoformat()
                sample_searches.append(row_dict)
            
            # Test the stats function
            stats = await db.get_user_stats(current_user)
            
            # Check table columns
            columns_info = await conn.fetch("""
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_name = 'search_history' AND table_schema = 'public'
                ORDER BY ordinal_position
            """)
            
            debug_info = {
                "user_exists": user_exists is not None,
                "user_mobile": current_user,
                "search_count_direct": search_count,
                "stats_function_result": stats,
                "sample_searches": sample_searches,
                "database_connected": db.pool is not None,
                "database_initialized": db._initialized,
                "table_columns": [{"name": col["column_name"], "type": col["data_type"]} for col in columns_info]
            }
            
            return JSONResponse({
                "success": True,
                "debug_info": debug_info
            })
            
    except Exception as e:
        logger.error(f"Debug endpoint error: {e}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

# Add this test data insertion endpoint
@app.post("/api/debug/add-test-data")
async def add_test_data(current_user: str = Depends(require_auth)):
    """Add test search data for debugging - FIXED for missing columns"""
    try:
        await db.initialize()
        
        # Check what columns exist first
        async with db.pool.acquire() as conn:
            existing_columns = await conn.fetch("""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = 'search_history' AND table_schema = 'public'
            """)
            
            column_names = {row['column_name'] for row in existing_columns}
            logger.info(f"Available columns for test data: {column_names}")
            
            # Add some test search history entries
            test_companies = [
                {"gstin": "29AAAPL2356Q1ZS", "name": "Test Company Alpha", "score": 85.5},
                {"gstin": "27AAAAA0000A1Z5", "name": "Test Company Beta", "score": 72.3},
                {"gstin": "07AAAAA0000A1Z5", "name": "Test Company Gamma", "score": 91.2},
                {"gstin": "33AAAAA0000A1Z5", "name": "Test Company Delta", "score": 68.7},
                {"gstin": "09AAAAA0000A1Z5", "name": "Test Company Epsilon", "score": 79.1},
            ]
            
            inserted_count = 0
            
            for company in test_companies:
                # Build insert with only existing columns
                columns = ['mobile', 'gstin', 'company_name', 'compliance_score']
                values = [current_user, company["gstin"], company["name"], company["score"]]
                placeholders = ['$1', '$2', '$3', '$4']
                
                # Add optional columns if they exist
                if 'search_data' in column_names:
                    columns.append('search_data')
                    values.append('{"test": true}')
                    placeholders.append(f'${len(values)}')
                
                if 'ai_synopsis' in column_names:
                    columns.append('ai_synopsis')
                    values.append(f"AI Analysis: {company['name']} shows good compliance trends with score of {company['score']}%")
                    placeholders.append(f'${len(values)}')
                
                query = f"""
                    INSERT INTO search_history ({', '.join(columns)})
                    VALUES ({', '.join(placeholders)})
                    ON CONFLICT (mobile, gstin) DO UPDATE SET
                        compliance_score = EXCLUDED.compliance_score,
                        company_name = EXCLUDED.company_name,
                        searched_at = CURRENT_TIMESTAMP
                """
                
                try:
                    await conn.execute(query, *values)
                    inserted_count += 1
                    logger.info(f"✅ Inserted test data for {company['gstin']}")
                except Exception as e:
                    logger.error(f"❌ Failed to insert {company['gstin']}: {e}")
        
        return JSONResponse({
            "success": True,
            "message": f"Added/updated {inserted_count} test entries",
            "test_data": test_companies,
            "available_columns": list(column_names)
        })
        
    except Exception as e:
        logger.error(f"Test data insertion error: {e}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        })

# Add this database table check/creation endpoint
# Add this to main.py - Replace the existing ensure-tables endpoint

@app.post("/api/debug/ensure-tables")
async def ensure_tables(current_user: str = Depends(require_auth)):
    """Ensure database tables exist with proper structure - FIXED"""
    try:
        await db.initialize()
        
        async with db.pool.acquire() as conn:
            # First, check what columns exist
            existing_columns = await conn.fetch("""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = 'search_history' AND table_schema = 'public'
            """)
            
            existing_column_names = {row['column_name'] for row in existing_columns}
            logger.info(f"Existing columns: {existing_column_names}")
            
            # Add missing columns one by one
            if 'ai_synopsis' not in existing_column_names:
                try:
                    await conn.execute("ALTER TABLE search_history ADD COLUMN ai_synopsis TEXT")
                    logger.info("✅ Added ai_synopsis column")
                except Exception as e:
                    logger.error(f"Failed to add ai_synopsis: {e}")
            
            if 'search_data' not in existing_column_names:
                try:
                    await conn.execute("ALTER TABLE search_history ADD COLUMN search_data JSONB DEFAULT '{}'")
                    logger.info("✅ Added search_data column")
                except Exception as e:
                    logger.error(f"Failed to add search_data: {e}")
            
            # Ensure other required columns exist
            required_columns = {
                'mobile': 'VARCHAR(15) NOT NULL',
                'gstin': 'VARCHAR(15) NOT NULL', 
                'company_name': 'TEXT',
                'compliance_score': 'DECIMAL(5,2)',
                'searched_at': 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'
            }
            
            for col_name, col_def in required_columns.items():
                if col_name not in existing_column_names:
                    try:
                        await conn.execute(f"ALTER TABLE search_history ADD COLUMN {col_name} {col_def}")
                        logger.info(f"✅ Added {col_name} column")
                    except Exception as e:
                        logger.error(f"Failed to add {col_name}: {e}")
            
            # Create index for better performance
            try:
                await conn.execute("""
                    CREATE INDEX IF NOT EXISTS idx_search_history_mobile_date 
                    ON search_history(mobile, searched_at DESC)
                """)
            except Exception as e:
                logger.error(f"Failed to create index: {e}")
            
            # Get final column list
            final_columns = await conn.fetch("""
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_name = 'search_history' 
                AND table_schema = 'public'
                ORDER BY ordinal_position
            """)
            
            return JSONResponse({
                "success": True,
                "message": "Database schema updated successfully",
                "columns": [{"name": col["column_name"], "type": col["data_type"]} for col in final_columns]
            })
            
    except Exception as e:
        logger.error(f"Schema update error: {e}")
        return JSONResponse({
            "success": False,
            "error": str(e)
        })    
# Startup/Shutdown
@app.on_event("startup")
async def startup_event():
    logger.info("🚀 Starting GST Intelligence Platform...")
    try:
        await db.initialize()
        setup_template_globals()
        
        # Add API debugging on startup
        if ENHANCED_APIS_AVAILABLE:
            logger.info("🔧 Running startup API diagnostics...")
            try:
                results = await debug_api_status()
                logger.info(f"📊 API Status: GST={'✅' if results.get('gst_api', {}).get('success') else '❌'}, "
                           f"AI={'✅' if results.get('anthropic_api', {}).get('success') else '❌'}")
            except Exception as e:
                logger.error(f"❌ Startup API diagnostics failed: {e}")
        else:
            logger.warning("⚠️ Enhanced API debugging not available")
            logger.info(f"📊 Basic API Check: GST={'✅' if api_client else '❌'}, "
                       f"AI={'✅' if ANTHROPIC_API_KEY else '❌'}")
        
        logger.info("✅ Application started successfully!")
    except Exception as e:
        logger.error(f"❌ Startup failed: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    logger.info("🛑 Shutting down GST Intelligence Platform...")
    if db.pool:
        await db.pool.close()
    logger.info("✅ Shutdown complete!")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)